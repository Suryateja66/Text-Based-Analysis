{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2f3294",
   "metadata": {},
   "source": [
    "# Import needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c7ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the stopwords module from the Natural Language Toolkit (nltk) corpus.\n",
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "# Import the cosine_distance function from the nltk.cluster.util module.\n",
    "# This function is used to calculate the cosine distance between two vectors.\n",
    "from nltk.cluster.util import cosine_distance\n",
    "# Import the numpy library and assign it the alias 'np'.\n",
    "# Numpy is a library for efficient numerical computation in Python.\n",
    "import numpy as np\n",
    "# Import the networkx library.\n",
    "# NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9b64f",
   "metadata": {},
   "source": [
    "# Open file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d60aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from data set to variable 'file' \n",
    "file = open(\"C:\\\\Users\\\\tejas\\\\Downloads\\\\Assignment Story.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f8c69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Il Ã©tait une fois, dans un pays trÃ¨s lointain, un royaume magique cachÃ© au plus profond dâ€™une forÃªt dense\n",
      "Le royaume s'appelait Â«TextoriaÂ» et Ã©tait gouvernÃ© par un roi sage et juste nommÃ© Â«NltkÂ»\n",
      "Le roi Nltk Ã©tait connu dans tout le pays pour sa remarquable capacitÃ© Ã  comprendre et Ã  analyser la langue de ses sujets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811ef5a",
   "metadata": {},
   "source": [
    "# Printing list of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8c7b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['ï»¿Il', 'Ã©tait', 'une', 'fois,', 'dans', 'un', 'pays', 'trÃ¨s', 'lointain,', 'un', 'royaume', 'magique', 'cachÃ©', 'au', 'plus', 'profond', 'dâ€™une', 'forÃªt', 'dense'], ['Le', 'royaume', \"s'appelait\", 'Â«TextoriaÂ»', 'et', 'Ã©tait', 'gouvernÃ©', 'par', 'un', 'roi', 'sage', 'et', 'juste', 'nommÃ©', 'Â«NltkÂ»'], ['Le', 'roi', 'Nltk', 'Ã©tait', 'connu', 'dans', 'tout', 'le', 'pays', 'pour', 'sa', 'remarquable', 'capacitÃ©', 'Ã\\xa0', 'comprendre', 'et', 'Ã\\xa0', 'analyser', 'la', 'langue', 'de', 'ses', 'sujets.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b0902",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0596673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd8783",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "284ac842",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c28215",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],\n",
    "sentences[idx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42eafdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.21170245 0.12598816]\n",
      " [0.21170245 0.         0.28005602]\n",
      " [0.12598816 0.28005602 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e731c83",
   "metadata": {},
   "source": [
    "# Getting the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4fb4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.2799345218306228, 1: 0.39168645855142875, 2: 0.32837901961794824}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6965",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495894a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.39168645855142875, ['Le', 'royaume', \"s'appelait\", 'Â«TextoriaÂ»', 'et', 'Ã©tait', 'gouvernÃ©', 'par', 'un', 'roi', 'sage', 'et', 'juste', 'nommÃ©', 'Â«NltkÂ»']), (0.32837901961794824, ['Le', 'roi', 'Nltk', 'Ã©tait', 'connu', 'dans', 'tout', 'le', 'pays', 'pour', 'sa', 'remarquable', 'capacitÃ©', 'Ã\\xa0', 'comprendre', 'et', 'Ã\\xa0', 'analyser', 'la', 'langue', 'de', 'ses', 'sujets.\\n']), (0.2799345218306228, ['ï»¿Il', 'Ã©tait', 'une', 'fois,', 'dans', 'un', 'pays', 'trÃ¨s', 'lointain,', 'un', 'royaume', 'magique', 'cachÃ©', 'au', 'plus', 'profond', 'dâ€™une', 'forÃªt', 'dense'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d96b39",
   "metadata": {},
   "source": [
    "# Pick the top “n” sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c030289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e8160",
   "metadata": {},
   "source": [
    "# Printing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bcf3632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Le royaume s'appelait Â«TextoriaÂ» et Ã©tait gouvernÃ© par un roi sage et juste nommÃ© Â«NltkÂ»\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14303f",
   "metadata": {},
   "source": [
    "# Using Different Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b2d2f",
   "metadata": {},
   "source": [
    "# Dutch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafdc0e",
   "metadata": {},
   "source": [
    "# Open file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6150bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from data set to variable 'file' \n",
    "file = open(\"C:\\\\Users\\\\tejas\\\\Downloads\\\\Dutch Story.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31014491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Er was eens, in een land ver, ver weg, een magisch koninkrijk diep verborgen in een dicht bos\n",
      "Het koninkrijk heette 'Textoria' en werd geregeerd door een wijze en rechtvaardige koning genaamd 'Nltk'\n",
      "Koning Nltk stond in het hele land bekend om zijn opmerkelijke vermogen om de taal van zijn onderdanen te begrijpen en te analyseren.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f3d20",
   "metadata": {},
   "source": [
    "# Printing list of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdff0670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['ï»¿Er', 'was', 'eens,', 'in', 'een', 'land', 'ver,', 'ver', 'weg,', 'een', 'magisch', 'koninkrijk', 'diep', 'verborgen', 'in', 'een', 'dicht', 'bos'], ['Het', 'koninkrijk', 'heette', \"'Textoria'\", 'en', 'werd', 'geregeerd', 'door', 'een', 'wijze', 'en', 'rechtvaardige', 'koning', 'genaamd', \"'Nltk'\"], ['Koning', 'Nltk', 'stond', 'in', 'het', 'hele', 'land', 'bekend', 'om', 'zijn', 'opmerkelijke', 'vermogen', 'om', 'de', 'taal', 'van', 'zijn', 'onderdanen', 'te', 'begrijpen', 'en', 'te', 'analyseren.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd836ade",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4686e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ad571",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ccc8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3696d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],\n",
    "sentences[idx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9614142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.1902606  0.10925356]\n",
      " [0.1902606  0.         0.18015094]\n",
      " [0.10925356 0.18015094 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd5998",
   "metadata": {},
   "source": [
    "# Getting the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c618640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.31415776925702044, 1: 0.3809512199286362, 2: 0.3048910108143429}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72099113",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a46f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3809512199286362, ['Het', 'koninkrijk', 'heette', \"'Textoria'\", 'en', 'werd', 'geregeerd', 'door', 'een', 'wijze', 'en', 'rechtvaardige', 'koning', 'genaamd', \"'Nltk'\"]), (0.31415776925702044, ['ï»¿Er', 'was', 'eens,', 'in', 'een', 'land', 'ver,', 'ver', 'weg,', 'een', 'magisch', 'koninkrijk', 'diep', 'verborgen', 'in', 'een', 'dicht', 'bos']), (0.3048910108143429, ['Koning', 'Nltk', 'stond', 'in', 'het', 'hele', 'land', 'bekend', 'om', 'zijn', 'opmerkelijke', 'vermogen', 'om', 'de', 'taal', 'van', 'zijn', 'onderdanen', 'te', 'begrijpen', 'en', 'te', 'analyseren.\\n'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1c584",
   "metadata": {},
   "source": [
    "# Pick the top “n” sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59a02606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522eb128",
   "metadata": {},
   "source": [
    "# Printing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523ec574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Het koninkrijk heette 'Textoria' en werd geregeerd door een wijze en rechtvaardige koning genaamd 'Nltk'. ï»¿Er was eens, in een land ver, ver weg, een magisch koninkrijk diep verborgen in een dicht bos\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c1617",
   "metadata": {},
   "source": [
    "# Japanese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7544c1",
   "metadata": {},
   "source": [
    "# Open file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cef8a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from data set to variable 'file' \n",
    "file = open(\"C:\\\\Users\\\\tejas\\\\Downloads\\\\Japanese Story.txt\", \"r\", encoding=\"utf-8\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f32846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿むかしむかし、遠い遠い国に、深い森の奥深くに隠された魔法の王国がありました。 その王国は「テクストリア」と呼ばれ、「Nltk」という名の賢明で正義の王が統治していました。 Nltk 王は、臣民の言語を理解し分析する驚くべき能力で国中に知られていました。ある日、勇敢な冒険者のグループが森の奥深くに隠された古代の遺物を発見しました。 そのアーティファクトは、蓋に奇妙なシンボルが刻まれた謎の箱でした。 記号には「コサイン距離」と書かれていました。 冒険者たちは好奇心をそそられ、箱を開けて中身を調べてみることにしました。箱を開けるとすぐに、まばゆい光が空間を満たし、箱から人影が現れました。 それは「ナンピー」という名の賢い老魔法使いでした。 ナンピーは数字とパターンの達人であり、現実の構造そのものを操作する力を持っていました。ナンピーは冒険者たちに、自分は何世紀にもわたって箱の中に閉じ込められ、適切な人物が解放してくれるのを待っていたと語った。 彼は、Nltk王の偉大な任務を手伝うためにテクストリアに派遣されたと説明した。 「ストップワーズ」としてのみ知られる闇の勢力が王国を悩ませ始め、言語の構造そのものを破壊する恐れがあった。ストップワードはあまり意味を持たない一般的な言葉でしたが、強力になり、王国中に急速に広まりました。 彼らは言語を破壊しており、Nltk王とその臣下が効果的に意思疎通することを困難にしていました。ナンピーは冒険者たちと力を合わせ、一緒にストップワードを倒すために出発した。 彼らは王国中を旅し、Numpy の力を使って言語を分析し、ストップワードを特定しました。 彼らは旅の途中で、強力な味方である「ネットワークx」という名の勇敢な戦士に出会いました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9af80",
   "metadata": {},
   "source": [
    "# Printing list of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd0b93f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['\\ufeffむかしむかし、遠い遠い国に、深い森の奥深くに隠された魔法の王国がありました。', 'その王国は「テクストリア」と呼ばれ、「Nltk」という名の賢明で正義の王が統治していました。', 'Nltk', '王は、臣民の言語を理解し分析する驚くべき能力で国中に知られていました。ある日、勇敢な冒険者のグループが森の奥深くに隠された古代の遺物を発見しました。', 'そのアーティファクトは、蓋に奇妙なシンボルが刻まれた謎の箱でした。', '記号には「コサイン距離」と書かれていました。', '冒険者たちは好奇心をそそられ、箱を開けて中身を調べてみることにしました。箱を開けるとすぐに、まばゆい光が空間を満たし、箱から人影が現れました。', 'それは「ナンピー」という名の賢い老魔法使いでした。', 'ナンピーは数字とパターンの達人であり、現実の構造そのものを操作する力を持っていました。ナンピーは冒険者たちに、自分は何世紀にもわたって箱の中に閉じ込められ、適切な人物が解放してくれるのを待っていたと語った。', '彼は、Nltk王の偉大な任務を手伝うためにテクストリアに派遣されたと説明した。', '「ストップワーズ」としてのみ知られる闇の勢力が王国を悩ませ始め、言語の構造そのものを破壊する恐れがあった。ストップワードはあまり意味を持たない一般的な言葉でしたが、強力になり、王国中に急速に広まりました。', '彼らは言語を破壊しており、Nltk王とその臣下が効果的に意思疎通することを困難にしていました。ナンピーは冒険者たちと力を合わせ、一緒にストップワードを倒すために出発した。', '彼らは王国中を旅し、Numpy', 'の力を使って言語を分析し、ストップワードを特定しました。', '彼らは旅の途中で、強力な味方である「ネットワークx」という名の勇敢な戦士に出会いました。\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4afdb98",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9d4e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d24cd",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d6856ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45644aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],\n",
    "sentences[idx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c657e75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ca6c4",
   "metadata": {},
   "source": [
    "# Getting the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1674a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870cfde",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7038c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(1.0, ['\\ufeffむかしむかし、遠い遠い国に、深い森の奥深くに隠された魔法の王国がありました。', 'その王国は「テクストリア」と呼ばれ、「Nltk」という名の賢明で正義の王が統治していました。', 'Nltk', '王は、臣民の言語を理解し分析する驚くべき能力で国中に知られていました。ある日、勇敢な冒険者のグループが森の奥深くに隠された古代の遺物を発見しました。', 'そのアーティファクトは、蓋に奇妙なシンボルが刻まれた謎の箱でした。', '記号には「コサイン距離」と書かれていました。', '冒険者たちは好奇心をそそられ、箱を開けて中身を調べてみることにしました。箱を開けるとすぐに、まばゆい光が空間を満たし、箱から人影が現れました。', 'それは「ナンピー」という名の賢い老魔法使いでした。', 'ナンピーは数字とパターンの達人であり、現実の構造そのものを操作する力を持っていました。ナンピーは冒険者たちに、自分は何世紀にもわたって箱の中に閉じ込められ、適切な人物が解放してくれるのを待っていたと語った。', '彼は、Nltk王の偉大な任務を手伝うためにテクストリアに派遣されたと説明した。', '「ストップワーズ」としてのみ知られる闇の勢力が王国を悩ませ始め、言語の構造そのものを破壊する恐れがあった。ストップワードはあまり意味を持たない一般的な言葉でしたが、強力になり、王国中に急速に広まりました。', '彼らは言語を破壊しており、Nltk王とその臣下が効果的に意思疎通することを困難にしていました。ナンピーは冒険者たちと力を合わせ、一緒にストップワードを倒すために出発した。', '彼らは王国中を旅し、Numpy', 'の力を使って言語を分析し、ストップワードを特定しました。', '彼らは旅の途中で、強力な味方である「ネットワークx」という名の勇敢な戦士に出会いました。\\n'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88459136",
   "metadata": {},
   "source": [
    "# Pick the top “n” sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9570fbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ef7a6",
   "metadata": {},
   "source": [
    "# Printing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b295db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " ﻿むかしむかし、遠い遠い国に、深い森の奥深くに隠された魔法の王国がありました。 その王国は「テクストリア」と呼ばれ、「Nltk」という名の賢明で正義の王が統治していました。 Nltk 王は、臣民の言語を理解し分析する驚くべき能力で国中に知られていました。ある日、勇敢な冒険者のグループが森の奥深くに隠された古代の遺物を発見しました。 そのアーティファクトは、蓋に奇妙なシンボルが刻まれた謎の箱でした。 記号には「コサイン距離」と書かれていました。 冒険者たちは好奇心をそそられ、箱を開けて中身を調べてみることにしました。箱を開けるとすぐに、まばゆい光が空間を満たし、箱から人影が現れました。 それは「ナンピー」という名の賢い老魔法使いでした。 ナンピーは数字とパターンの達人であり、現実の構造そのものを操作する力を持っていました。ナンピーは冒険者たちに、自分は何世紀にもわたって箱の中に閉じ込められ、適切な人物が解放してくれるのを待っていたと語った。 彼は、Nltk王の偉大な任務を手伝うためにテクストリアに派遣されたと説明した。 「ストップワーズ」としてのみ知られる闇の勢力が王国を悩ませ始め、言語の構造そのものを破壊する恐れがあった。ストップワードはあまり意味を持たない一般的な言葉でしたが、強力になり、王国中に急速に広まりました。 彼らは言語を破壊しており、Nltk王とその臣下が効果的に意思疎通することを困難にしていました。ナンピーは冒険者たちと力を合わせ、一緒にストップワードを倒すために出発した。 彼らは王国中を旅し、Numpy の力を使って言語を分析し、ストップワードを特定しました。 彼らは旅の途中で、強力な味方である「ネットワークx」という名の勇敢な戦士に出会いました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe06be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
